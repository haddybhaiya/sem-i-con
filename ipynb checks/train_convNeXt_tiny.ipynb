{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPbjkoPzKWzdGi3QPJCJvxr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d5f77d377d3941fb88c981a2e36db4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bd977a1991cc4aa09ced1c45e52871df",
              "IPY_MODEL_a8c9979cabb449e997ca4ffbed010713",
              "IPY_MODEL_9aaac2b870364ced99b1fec0e4859d56"
            ],
            "layout": "IPY_MODEL_24d604b4a87b474ca77673609bdb9f4c"
          }
        },
        "bd977a1991cc4aa09ced1c45e52871df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5d38215bd3441d0ac7fb8ccbaf9e23e",
            "placeholder": "​",
            "style": "IPY_MODEL_6cc23b6c73a4477d9422337498e35b02",
            "value": "model.safetensors: 100%"
          }
        },
        "a8c9979cabb449e997ca4ffbed010713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76ae407146894d60ba1b94f97cdc6d71",
            "max": 114374272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa7379b03125493fa8bd474fb18f4ea8",
            "value": 114374272
          }
        },
        "9aaac2b870364ced99b1fec0e4859d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fedafb833cd1428db9191916be567d15",
            "placeholder": "​",
            "style": "IPY_MODEL_9413e233efdb4cfabc81a63f15600c19",
            "value": " 114M/114M [00:02&lt;00:00, 84.7MB/s]"
          }
        },
        "24d604b4a87b474ca77673609bdb9f4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5d38215bd3441d0ac7fb8ccbaf9e23e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc23b6c73a4477d9422337498e35b02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76ae407146894d60ba1b94f97cdc6d71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa7379b03125493fa8bd474fb18f4ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fedafb833cd1428db9191916be567d15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9413e233efdb4cfabc81a63f15600c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haddybhaiya/sem-i-con/blob/main/train_convNeXt_tiny.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EXoEEI7r7DVc",
        "outputId": "1260db7b-78cf-42a5-a1a3-9b6cceeba4fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.24)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.24.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (1.3.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (3.20.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (0.21.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm) (11.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm) (0.16.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub->timm) (8.3.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm\n",
        "!pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYPmGmmm7Te7",
        "outputId": "4cdf9f3c-1ba1-435a-94a4-2a201ead45ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "AdOA_IXW7aFX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/synthetic_dataset\"   # change if needed\n",
        "NUM_CLASSES = 8\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 20\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "CLASSES = [\n",
        "    \"clean\",\"bridge\",\"cmp\",\"crack\",\"open\",\"ler\",\"via\",\"other\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "3skHQ-wq7kJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SEMDataset(Dataset):\n",
        "    def __init__(self, samples):\n",
        "        self.samples = samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, cls = self.samples[idx]\n",
        "\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        img = img.astype(np.float32) / 255.0\n",
        "\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "\n",
        "        label = CLASSES.index(cls)\n",
        "\n",
        "        return torch.tensor(img), torch.tensor(label)\n"
      ],
      "metadata": {
        "id": "pitWkuSu7x3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "all_samples = []\n",
        "\n",
        "for cls in CLASSES:\n",
        "    folder = os.path.join(DATASET_PATH, cls)\n",
        "\n",
        "    for img in os.listdir(folder):\n",
        "        all_samples.append((os.path.join(folder, img), cls))\n",
        "\n",
        "train_samples, val_samples = train_test_split(\n",
        "    all_samples,\n",
        "    test_size=0.2,\n",
        "    stratify=[s[1] for s in all_samples],   # keeps class balance\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train:\", len(train_samples))\n",
        "print(\"Val:\", len(val_samples))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClS8lc3C71my",
        "outputId": "70d25f61-2946-4355-c7bc-e038d5c75b73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1920\n",
            "Val: 480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SEMDataset(train_samples)\n",
        "val_dataset   = SEMDataset(val_samples)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"
      ],
      "metadata": {
        "id": "KUXuvwJr8mY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_convnext().to(DEVICE)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "d5f77d377d3941fb88c981a2e36db4a5",
            "bd977a1991cc4aa09ced1c45e52871df",
            "a8c9979cabb449e997ca4ffbed010713",
            "9aaac2b870364ced99b1fec0e4859d56",
            "24d604b4a87b474ca77673609bdb9f4c",
            "d5d38215bd3441d0ac7fb8ccbaf9e23e",
            "6cc23b6c73a4477d9422337498e35b02",
            "76ae407146894d60ba1b94f97cdc6d71",
            "fa7379b03125493fa8bd474fb18f4ea8",
            "fedafb833cd1428db9191916be567d15",
            "9413e233efdb4cfabc81a63f15600c19"
          ]
        },
        "id": "vbppY-zq9dee",
        "outputId": "d50aad03-eee7-4d72-d595-75f60ac07349"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5f77d377d3941fb88c981a2e36db4a5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for x, y in tqdm(train_loader):\n",
        "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        out = model(x)\n",
        "        loss = criterion(out, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1} Loss:\", total_loss / len(train_loader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y51HfSDh9jMO",
        "outputId": "c19b7257-c4fe-41bf-c1da-b9d59c564177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [21:58<00:00, 10.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 0.25449785136200564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:41<00:00,  2.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 Loss: 0.03702565324122891\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:40<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 Loss: 0.013663354355321644\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:41<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 Loss: 0.0025174609759233135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:41<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 Loss: 7.263057671783221e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:41<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 Loss: 3.920390437694247e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:40<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 Loss: 2.9905097881055555e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:40<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 Loss: 2.381059314302547e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:41<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 Loss: 1.9478914578030525e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:41<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 Loss: 1.6277008057841158e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:40<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 Loss: 1.3809070946990686e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:40<00:00,  2.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 Loss: 1.1877049848862952e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:41<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 Loss: 1.0320555869232825e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:40<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 Loss: 9.044484075578415e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:41<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 Loss: 7.981408517328721e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:40<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 Loss: 7.096141278376914e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:41<00:00,  2.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 Loss: 6.337951964496824e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:40<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 Loss: 5.684935202528626e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:40<00:00,  2.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 Loss: 5.126411087985616e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 120/120 [00:41<00:00,  2.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 Loss: 4.630343515070005e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in val_loader:\n",
        "        x = x.to(DEVICE)\n",
        "\n",
        "        out = model(x)\n",
        "        preds = torch.argmax(out, dim=1).cpu()\n",
        "\n",
        "        all_preds.extend(preds.numpy())\n",
        "        all_labels.extend(y.numpy())\n",
        "\n",
        "print(classification_report(all_labels, all_preds, target_names=CLASSES))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihlOXT5d9oCQ",
        "outputId": "06b40a9a-4ac4-4bb3-fcc4-acf58e2d6e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       clean       1.00      1.00      1.00        60\n",
            "      bridge       1.00      1.00      1.00        60\n",
            "         cmp       1.00      1.00      1.00        60\n",
            "       crack       1.00      1.00      1.00        60\n",
            "        open       1.00      1.00      1.00        60\n",
            "         ler       1.00      1.00      1.00        60\n",
            "         via       1.00      1.00      1.00        60\n",
            "       other       1.00      1.00      1.00        60\n",
            "\n",
            "    accuracy                           1.00       480\n",
            "   macro avg       1.00      1.00      1.00       480\n",
            "weighted avg       1.00      1.00      1.00       480\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"convnext_sem.pth\")\n",
        "print(\"Model saved\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl_HDnMP9vyZ",
        "outputId": "76b5c762-aee1-4331-ccb6-410783908c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime\n",
        "!pip install onnx\n",
        "!pip install onnxscript"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03OyjMMRJAsz",
        "outputId": "a8412824-1d5e-42f5-d452-fe29d60b07dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.12.19)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime) (1.14.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.23.2\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.12/dist-packages (from onnx) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (5.29.5)\n",
            "Requirement already satisfied: typing_extensions>=4.7.1 in /usr/local/lib/python3.12/dist-packages (from onnx) (4.15.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from onnx) (0.5.4)\n",
            "Downloading onnx-1.20.1-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.5/17.5 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx\n",
            "Successfully installed onnx-1.20.1\n",
            "Collecting onnxscript\n",
            "  Downloading onnxscript-0.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: ml_dtypes in /usr/local/lib/python3.12/dist-packages (from onnxscript) (0.5.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from onnxscript) (2.0.2)\n",
            "Collecting onnx_ir<2,>=0.1.15 (from onnxscript)\n",
            "  Downloading onnx_ir-0.1.15-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: onnx>=1.17 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (1.20.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from onnxscript) (25.0)\n",
            "Requirement already satisfied: typing_extensions>=4.10 in /usr/local/lib/python3.12/dist-packages (from onnxscript) (4.15.0)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.12/dist-packages (from onnx>=1.17->onnxscript) (5.29.5)\n",
            "Downloading onnxscript-0.6.0-py3-none-any.whl (689 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m689.1/689.1 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx_ir-0.1.15-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.7/148.7 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: onnx_ir, onnxscript\n",
            "Successfully installed onnx_ir-0.1.15 onnxscript-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "import os\n",
        "\n",
        "MODEL_PATH = \"/content/convnext_sem.pth\"\n",
        "ONNX_PATH = \"sem.onnx\"\n",
        "\n",
        "NUM_CLASSES = 8\n",
        "IMG_SIZE = 224\n",
        "DEVICE = \"cpu\"\n",
        "\n",
        "CLASSES = [\"clean\",\"bridge\",\"cmp\",\"crack\",\"open\",\"ler\",\"via\",\"other\"]\n",
        "\n",
        "# ---- Build Model ----\n",
        "model = timm.create_model(\"convnext_tiny\", pretrained=False, in_chans=1)\n",
        "model.head.fc = nn.Linear(model.head.fc.in_features, NUM_CLASSES)\n",
        "\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
        "model.eval()\n",
        "\n",
        "dummy_input = torch.randn(1, 1, IMG_SIZE, IMG_SIZE)\n",
        "\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    ONNX_PATH,\n",
        "    input_names=[\"input\"],\n",
        "    output_names=[\"output\"],\n",
        "    opset_version=17,\n",
        "    dynamic_axes={\"input\": {0: \"batch\"}, \"output\": {0: \"batch\"}},\n",
        ")\n",
        "\n",
        "print(\"✅ FP32 ONNX exported:\", ONNX_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fyUlF2dHhQI",
        "outputId": "3d7f4eb2-21dc-4ffb-bf03-4d8d2a506830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3497153173.py:24: UserWarning: # 'dynamic_axes' is not recommended when dynamo=True, and may lead to 'torch._dynamo.exc.UserError: Constraints violated.' Supply the 'dynamic_shapes' argument instead if export is unsuccessful.\n",
            "  torch.onnx.export(\n",
            "W0203 10:55:42.174000 800 torch/onnx/_internal/exporter/_compat.py:114] Setting ONNX exporter to use operator set version 18 because the requested opset_version 17 is a lower version than we have implementations for. Automatic version conversion will be performed, which may not be successful at converting to the requested version. If version conversion is unsuccessful, the opset version of the exported model will be kept at 18. Please consider setting opset_version >=18 to leverage latest ONNX features\n",
            "W0203 10:55:43.365000 800 torch/onnx/_internal/exporter/_schemas.py:455] Missing annotation for parameter 'input' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0, sampling_ratio: 'int' = -1, aligned: 'bool' = False). Treating as an Input.\n",
            "W0203 10:55:43.367000 800 torch/onnx/_internal/exporter/_schemas.py:455] Missing annotation for parameter 'boxes' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0, sampling_ratio: 'int' = -1, aligned: 'bool' = False). Treating as an Input.\n",
            "W0203 10:55:43.369000 800 torch/onnx/_internal/exporter/_schemas.py:455] Missing annotation for parameter 'input' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0). Treating as an Input.\n",
            "W0203 10:55:43.371000 800 torch/onnx/_internal/exporter/_schemas.py:455] Missing annotation for parameter 'boxes' from (input, boxes, output_size: 'Sequence[int]', spatial_scale: 'float' = 1.0). Treating as an Input.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Obtain model graph for `ConvNeXt([...]` with `torch.export.export(..., strict=False)`...\n",
            "[torch.onnx] Obtain model graph for `ConvNeXt([...]` with `torch.export.export(..., strict=False)`... ✅\n",
            "[torch.onnx] Run decomposition...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.version_converter:The model version conversion is not supported by the onnxscript version converter and fallback is enabled. The model will be converted using the onnx C API (target version: 17).\n",
            "WARNING:onnxscript.version_converter:Failed to convert the model to the target version 17 using the ONNX C API. The model was not modified\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 127, in call\n",
            "    converted_proto = _c_api_utils.call_onnx_api(\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/_c_api_utils.py\", line 65, in call_onnx_api\n",
            "    result = func(proto)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnxscript/version_converter/__init__.py\", line 122, in _partial_convert_version\n",
            "    return onnx.version_converter.convert_version(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/onnx/version_converter.py\", line 39, in convert_version\n",
            "    converted_model_str = C.convert_version(model_str, target_version)\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: /github/workspace/onnx/version_converter/adapters/axes_input_to_attribute.h:65: adapt: Assertion `node->hasAttribute(kaxes)` failed: No initializer or constant input to node found\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[torch.onnx] Run decomposition... ✅\n",
            "[torch.onnx] Translate the graph into ONNX...\n",
            "[torch.onnx] Translate the graph into ONNX... ✅\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:onnxscript.optimizer._constant_folding:Skipping constant folding for op SequenceEmpty with multiple outputs.\n",
            "WARNING:onnxscript.optimizer._constant_folding:Skipping constant folding for op SequenceEmpty with multiple outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ FP32 ONNX exported: sem.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "\n",
        "MODEL_PATH = \"convnext_sem.pth\"\n",
        "OUT_PATH = \"sem_int8.pth\"\n",
        "NUM_CLASSES = 8\n",
        "\n",
        "device = \"cpu\"\n",
        "\n",
        "# Build model\n",
        "model = timm.create_model(\n",
        "    \"convnext_tiny\",\n",
        "    pretrained=False,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    in_chans=1\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
        "model.eval()\n",
        "\n",
        "# ---- Dynamic quantization ----\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model,\n",
        "    {nn.Linear},\n",
        "    dtype=torch.qint8\n",
        ")\n",
        "\n",
        "torch.save(quantized_model.state_dict(), OUT_PATH)\n",
        "\n",
        "print(\"✅ Torch INT8 model saved:\", OUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUwQc8i5MClU",
        "outputId": "7cb633b8-aa70-48bf-be3c-3a81dc8a679a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3074260091.py:23: DeprecationWarning: torch.ao.quantization is deprecated and will be removed in 2.10. \n",
            "For migrations of users: \n",
            "1. Eager mode quantization (torch.ao.quantization.quantize, torch.ao.quantization.quantize_dynamic), please migrate to use torchao eager mode quantize_ API instead \n",
            "2. FX graph mode quantization (torch.ao.quantization.quantize_fx.prepare_fx,torch.ao.quantization.quantize_fx.convert_fx, please migrate to use torchao pt2e quantization API instead (prepare_pt2e, convert_pt2e) \n",
            "3. pt2e quantization has been migrated to torchao (https://github.com/pytorch/ao/tree/main/torchao/quantization/pt2e) \n",
            "see https://github.com/pytorch/ao/issues/2259 for more details\n",
            "  quantized_model = torch.quantization.quantize_dynamic(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Torch INT8 model saved: sem_int8.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import timm\n",
        "\n",
        "MODEL_PATH = \"sem_int8.pth\"\n",
        "OUT_PATH = \"sem_int8.pt\"\n",
        "NUM_CLASSES = 8\n",
        "\n",
        "model = timm.create_model(\n",
        "    \"convnext_tiny\",\n",
        "    pretrained=False,\n",
        "    num_classes=NUM_CLASSES,\n",
        "    in_chans=1\n",
        ")\n",
        "\n",
        "model.load_state_dict(torch.load(MODEL_PATH, map_location=\"cpu\"))\n",
        "model.eval()\n",
        "\n",
        "example = torch.randn(1,1,224,224)\n",
        "\n",
        "scripted = torch.jit.trace(model, example)\n",
        "scripted.save(OUT_PATH)\n",
        "\n",
        "print(\"✅ TorchScript INT8 exported:\", OUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "id": "Pe9_3csHKzB8",
        "outputId": "a4819290-3654-4ed1-bb8b-2acf57a7302c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Error(s) in loading state_dict for ConvNeXt:\n\tMissing key(s) in state_dict: \"stages.0.blocks.0.mlp.fc1.weight\", \"stages.0.blocks.0.mlp.fc1.bias\", \"stages.0.blocks.0.mlp.fc2.weight\", \"stages.0.blocks.0.mlp.fc2.bias\", \"stages.0.blocks.1.mlp.fc1.weight\", \"stages.0.blocks.1.mlp.fc1.bias\", \"stages.0.blocks.1.mlp.fc2.weight\", \"stages.0.blocks.1.mlp.fc2.bias\", \"stages.0.blocks.2.mlp.fc1.weight\", \"stages.0.blocks.2.mlp.fc1.bias\", \"stages.0.blocks.2.mlp.fc2.weight\", \"stages.0.blocks.2.mlp.fc2.bias\", \"stages.1.blocks.0.mlp.fc1.weight\", \"stages.1.blocks.0.mlp.fc1.bias\", \"stages.1.blocks.0.mlp.fc2.weight\", \"stages.1.blocks.0.mlp.fc2.bias\", \"stages.1.blocks.1.mlp.fc1.weight\", \"stages.1.blocks.1.mlp.fc1.bias\", \"stages.1.blocks.1.mlp.fc2.weight\", \"stages.1.blocks.1.mlp.fc2.bias\", \"stages.1.blocks.2.mlp.fc1.weight\", \"stages.1.blocks.2.mlp.fc1.bias\", \"stages.1.blocks.2.mlp.fc2.weight\", \"stages.1.blocks.2.mlp.fc2.bias\", \"stages.2.blocks.0.mlp.fc1.weight\", \"stages.2.blocks.0.mlp.fc1.bias\", \"stages.2.blocks.0.mlp.fc2.weight\", \"stages.2.blocks.0.mlp.fc2.bias\", \"stages.2.blocks.1.mlp.fc1.weight\", \"stages.2.blocks.1.mlp.fc1.bias\", \"stages.2.blocks.1.mlp.fc2.weight\", \"stages.2.blocks.1.mlp.fc2.bias\", \"stages.2.blocks.2.mlp.fc1.weight\", \"stages.2.blocks.2.mlp.fc1.bias\", \"stages.2.blocks.2.mlp.fc2.weight\", \"stages.2.blocks.2.mlp.fc2.bias\", \"stages.2.blocks.3.mlp.fc1.weight\", \"stages.2.blocks.3.mlp.fc1.bias\", \"stages.2.blocks.3.mlp.fc2.weight\", \"stages.2.blocks.3.mlp.fc2.bias\", \"stages.2.blocks.4.mlp.fc1.weight\", \"stages.2.blocks.4.mlp.fc1.bias\", \"stages.2.blocks.4.mlp.fc2.weight\", \"stages.2.blocks.4.mlp.fc2.bias\", \"stages.2.blocks.5.mlp.fc1.weight\", \"stages.2.blocks.5.mlp.fc1.bias\", \"stages.2.blocks.5.mlp.fc2.weight\", \"stages.2.blocks.5.mlp.fc2.bias\", \"stages.2.blocks.6.mlp.fc1.weight\", \"stages.2.blocks.6.mlp.fc1.bias\", \"stages.2.blocks.6.mlp.fc2.weight\", \"stages.2.blocks.6.mlp.fc2.bias\", \"stages.2.blocks.7.mlp.fc1.weight\", \"stages.2.blocks.7.mlp.fc1.bias\", \"stages.2.blocks.7.mlp.fc2.weight\", \"stages.2.blocks.7.mlp.fc2.bias\", \"stages.2.blocks.8.mlp.fc1.weight\", \"stages.2.blocks.8.mlp.fc1.bias\", \"stages.2.blocks.8.mlp.fc2.weight\", \"stages.2.blocks.8.mlp.fc2.bias\", \"stages.3.blocks.0.mlp.fc1.weight\", \"stages.3.blocks.0.mlp.fc1.bias\", \"stages.3.blocks.0.mlp.fc2.weight\", \"stages.3.blocks.0.mlp.fc2.bias\", \"stages.3.blocks.1.mlp.fc1.weight\", \"stages.3.blocks.1.mlp.fc1.bias\", \"stages.3.blocks.1.mlp.fc2.weight\", \"stages.3.blocks.1.mlp.fc2.bias\", \"stages.3.blocks.2.mlp.fc1.weight\", \"stages.3.blocks.2.mlp.fc1.bias\", \"stages.3.blocks.2.mlp.fc2.weight\", \"stages.3.blocks.2.mlp.fc2.bias\", \"head.fc.weight\", \"head.fc.bias\". \n\tUnexpected key(s) in state_dict: \"stages.0.blocks.0.mlp.fc1.scale\", \"stages.0.blocks.0.mlp.fc1.zero_point\", \"stages.0.blocks.0.mlp.fc1._packed_params.dtype\", \"stages.0.blocks.0.mlp.fc1._packed_params._packed_params\", \"stages.0.blocks.0.mlp.fc2.scale\", \"stages.0.blocks.0.mlp.fc2.zero_point\", \"stages.0.blocks.0.mlp.fc2._packed_params.dtype\", \"stages.0.blocks.0.mlp.fc2._packed_params._packed_params\", \"stages.0.blocks.1.mlp.fc1.scale\", \"stages.0.blocks.1.mlp.fc1.zero_point\", \"stages.0.blocks.1.mlp.fc1._packed_params.dtype\", \"stages.0.blocks.1.mlp.fc1._packed_params._packed_params\", \"stages.0.blocks.1.mlp.fc2.scale\", \"stages.0.blocks.1.mlp.fc2.zero_point\", \"stages.0.blocks.1.mlp.fc2._packed_params.dtype\", \"stages.0.blocks.1.mlp.fc2._packed_params._packed_params\", \"stages.0.blocks.2.mlp.fc1.scale\", \"stages.0.blocks.2.mlp.fc1.zero_point\", \"stages.0.blocks.2.mlp.fc1._packed_params.dtype\", \"stages.0.blocks.2.mlp.fc1._packed_params._packed_params\", \"stages.0.blocks.2.mlp.fc2.scale\", \"stages.0.blocks.2.mlp.fc2.zero_point\", \"stages.0.blocks.2.mlp.fc2._packed_params.dtype\", \"stages.0.blocks.2.mlp.fc2._packed_params._packed_params\", \"stages.1.blocks.0.mlp.fc1.scale\", \"stages.1.blocks.0.mlp.fc1.zero_point\", \"stages.1.blocks.0.mlp.fc1._packed_params.dtype\", \"stages.1.blocks.0.mlp.fc1._packed_params._packed_params\", \"stages.1.blocks.0.mlp.fc2.scale\", \"stages.1.blocks.0.mlp.fc2.zero_point\", \"stages.1.blocks.0.mlp.fc2._packed_params.dtype\", \"stages.1.blocks.0.mlp.fc2._packed_params._packed_params\", \"stages.1.blocks.1.mlp.fc1.scale\", \"stages.1.blocks.1.mlp.fc1.zero_point\", \"stages.1.blocks.1.mlp.fc1._packed_params.dtype\", \"stages.1.blocks.1.mlp.fc1._packed_params._packed_params\", \"stages.1.blocks.1.mlp.fc2.scale\", \"stages.1.blocks.1.mlp.fc2.zero_point\", \"stages.1.blocks.1.mlp.fc2._packed_params.dtype\", \"stages.1.blocks.1.mlp.fc2._packed_params._packed_params\", \"stages.1.blocks.2.mlp.fc1.scale\", \"stages.1.blocks.2.mlp.fc1.zero_point\", \"stages.1.blocks.2.mlp.fc1._packed_params.dtype\", \"stages.1.blocks.2.mlp.fc1._packed_params._packed_params\", \"stages.1.blocks.2.mlp.fc2.scale\", \"stages.1.blocks.2.mlp.fc2.zero_point\", \"stages.1.blocks.2.mlp.fc2._packed_params.dtype\", \"stages.1.blocks.2.mlp.fc2._packed_params._packed_params\", \"stages.2.blocks.0.mlp.fc1.scale\", \"stages.2.blocks.0.mlp.fc1.zero_point\", \"stages.2.blocks.0.mlp.fc1._packed_params.dtype\", \"stages.2.blocks.0.mlp.fc1._packed_params._packed_params\", \"stages.2.blocks.0.mlp.fc2.scale\", \"stages.2.blocks.0.mlp.fc2.zero_point\", \"stages.2.blocks.0.mlp.fc2._packed_params.dtype\", \"stages.2.blocks.0.mlp.fc2._packed_params._packed_params\", \"stages.2.blocks.1.mlp.fc1.scale\", \"stages.2.blocks.1.mlp.fc1.zero_point\", \"stages.2.blocks.1.mlp.fc1._packed_params.dtype\", \"stages.2.blocks.1.mlp.fc1._packed_params._packed_params\", \"stages.2.blocks.1.mlp.fc2.scale\", \"stages.2.blocks.1.mlp.fc2.zero_point\", \"stages.2.blocks.1.mlp.fc2._packed_params.dtype\", \"stages.2.blocks.1.mlp.fc2._packed_params._packed_params\", \"stages.2.blocks.2.mlp.fc1.scale\", \"stages.2.blocks.2.mlp.fc1.zero_point\", \"stages.2.blocks.2.mlp.fc1._packed_params.dtype\", \"stages.2.blocks.2.mlp.fc1._packed_params._packed_params\", \"stages.2.blocks.2.mlp.fc2.scale\", \"stages.2.blocks.2.mlp.fc2.zero_point\", \"stages.2.blocks.2.mlp.fc2._packed_params.dtype\", \"stages.2.blocks.2.mlp.fc2._packed_params._packed_params\", \"stages.2.blocks.3.mlp.fc1.scale\", \"stages.2.blocks.3.mlp.fc1.zero_point\", \"stages.2.blocks.3.mlp.fc1._packed_params.dtype\", \"stages.2.blocks.3.mlp.fc1._packed_params._packed_params\", \"stages.2.blocks.3.mlp.fc2.scale\", \"stages.2.blocks.3.mlp.fc2.zero_point\", \"stages.2.blocks.3.mlp.fc2._packed_params.dtype\", \"stages.2.blocks.3.mlp.fc2._packed_params._packed_params\", \"stages.2.blocks.4.mlp.fc1.scale\", \"stages.2.blocks.4.mlp.fc1.zero_point\", \"stages.2.blocks.4.mlp.fc1._packed_params.dtype\", \"stages.2.blocks.4.mlp.fc1._packed_params._packed_params\", \"stages.2.blocks.4.mlp.fc2.scale\", \"stages.2.blocks.4.mlp.fc2.zero_point\", \"stages.2.blocks.4.mlp.fc2._packed_params.dtype\", \"stages.2.blocks.4.mlp.fc2._packed_params._packed_params\", \"stages.2.blocks.5.mlp.fc1.scale\", \"stages.2.blocks.5.mlp.fc1.zero_point\", \"stages.2.blocks.5.mlp.fc1._packed_params.dtype\", \"stages.2.blocks.5.mlp.fc1._packed_params._packed_params\", \"stages.2.blocks.5.mlp.fc2.scale\", \"stages.2.blocks.5.mlp.fc2.zero_point\", \"stages.2.blocks.5.mlp.fc2._packed_params.dtype\", \"stages.2.blocks.5.mlp.fc2._packed_params._packed_params\", \"stages.2.blocks.6.mlp.fc1.scale\", \"stages.2.blocks.6.mlp.fc1.zero_point\", \"stages.2.blocks.6.mlp.fc1._packed_params.dtype\", \"stages.2.blocks.6.mlp.fc1._packed_params._packed_params\", \"stages.2.blocks.6.mlp.fc2.scale\", \"stages.2.blocks.6.mlp.fc2.zero_point\", \"stages.2.blocks.6.mlp.fc2._packed_params.dtype\", \"stages.2.blocks.6.mlp.fc2._packed_params._packed_params\", \"stages.2.blocks.7.mlp.fc1.scale\", \"stages.2.blocks.7.mlp.fc1.zero_point\", \"stages.2.blocks.7.mlp.fc1._packed_params.dtype\", \"stages.2.blocks.7.mlp.fc1._packed_params._packed_params\", \"stages.2.blocks.7.mlp.fc2.scale\", \"stages.2.blocks.7.mlp.fc2.zero_point\", \"stages.2.blocks.7.mlp.fc2._packed_params.dtype\", \"stages.2.blocks.7.mlp.fc2._packed_params._packed_params\", \"stages.2.blocks.8.mlp.fc1.scale\", \"stages.2.blocks.8.mlp.fc1.zero_point\", \"stages.2.blocks.8.mlp.fc1._packed_params.dtype\", \"stages.2.blocks.8.mlp.fc1._packed_params._packed_params\", \"stages.2.blocks.8.mlp.fc2.scale\", \"stages.2.blocks.8.mlp.fc2.zero_point\", \"stages.2.blocks.8.mlp.fc2._packed_params.dtype\", \"stages.2.blocks.8.mlp.fc2._packed_params._packed_params\", \"stages.3.blocks.0.mlp.fc1.scale\", \"stages.3.blocks.0.mlp.fc1.zero_point\", \"stages.3.blocks.0.mlp.fc1._packed_params.dtype\", \"stages.3.blocks.0.mlp.fc1._packed_params._packed_params\", \"stages.3.blocks.0.mlp.fc2.scale\", \"stages.3.blocks.0.mlp.fc2.zero_point\", \"stages.3.blocks.0.mlp.fc2._packed_params.dtype\", \"stages.3.blocks.0.mlp.fc2._packed_params._packed_params\", \"stages.3.blocks.1.mlp.fc1.scale\", \"stages.3.blocks.1.mlp.fc1.zero_point\", \"stages.3.blocks.1.mlp.fc1._packed_params.dtype\", \"stages.3.blocks.1.mlp.fc1._packed_params._packed_params\", \"stages.3.blocks.1.mlp.fc2.scale\", \"stages.3.blocks.1.mlp.fc2.zero_point\", \"stages.3.blocks.1.mlp.fc2._packed_params.dtype\", \"stages.3.blocks.1.mlp.fc2._packed_params._packed_params\", \"stages.3.blocks.2.mlp.fc1.scale\", \"stages.3.blocks.2.mlp.fc1.zero_point\", \"stages.3.blocks.2.mlp.fc1._packed_params.dtype\", \"stages.3.blocks.2.mlp.fc1._packed_params._packed_params\", \"stages.3.blocks.2.mlp.fc2.scale\", \"stages.3.blocks.2.mlp.fc2.zero_point\", \"stages.3.blocks.2.mlp.fc2._packed_params.dtype\", \"stages.3.blocks.2.mlp.fc2._packed_params._packed_params\", \"head.fc.scale\", \"head.fc.zero_point\", \"head.fc._packed_params.dtype\", \"head.fc._packed_params._packed_params\". ",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4132101868.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2629\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2630\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2631\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ConvNeXt:\n\tMissing key(s) in state_dict: \"stages.0.blocks.0.mlp.fc1.weight\", \"stages.0.blocks.0.mlp.fc1.bias\", \"stages.0.blocks.0.mlp.fc2.weight\", \"stages.0.blocks.0.mlp.fc2.bias\", \"stages.0.blocks.1.mlp.fc1.weight\", \"stages.0.blocks.1.mlp.fc1.bias\", \"stages.0.blocks.1.mlp.fc2.weight\", \"stages.0.blocks.1.mlp.fc2.bias\", \"stages.0.blocks.2.mlp.fc1.weight\", \"stages.0.blocks.2.mlp.fc1.bias\", \"stages.0.blocks.2.mlp.fc2.weight\", \"stages.0.blocks.2.mlp.fc2.bias\", \"stages.1.blocks.0.mlp.fc1.weight\", \"stages.1.blocks.0.mlp.fc1.bias\", \"stages.1.blocks.0.mlp.fc2.weight\", \"stages.1.blocks.0.mlp.fc2.bias\", \"stages.1.blocks.1.mlp.fc1.weight\", \"stages.1.blocks.1.mlp.fc1.bias\", \"stages.1.blocks.1.mlp.fc2.weight\", \"stages.1.blocks.1.mlp.fc2.bias\", \"stages.1.blocks.2.mlp.fc1.weight\", \"stages.1.blocks.2.mlp.fc1.bias\", \"stages.1.blocks.2.mlp.fc2.weight\", \"stages.1.blocks.2.mlp.fc2.bias\", \"stages.2.blocks.0.mlp.fc1.weight\", \"stages.2.blocks.0.mlp.fc1.bias\", \"stages.2.blocks.0.mlp.fc2.weight\", \"stages.2.blocks.0.mlp.fc2.bias\", \"stages.2.blocks.1.mlp.fc1.weight\", \"stages.2.blocks.1.mlp.fc1.bias\", \"stages.2.blocks.1.mlp.fc2.weight\", \"stages.2.blocks.1.mlp.fc2.bias\", \"stages.2.blocks.2.mlp.fc1.weight\", \"stages.2.blocks.2.mlp.fc1.bias\", \"stages.2.blocks.2.mlp.fc2.weight\", \"stages.2.blocks.2.mlp.fc2.bias\", \"stages.2.blocks.3.mlp.fc1.weight\", \"stages.2.blocks.3.mlp.fc1.bias\", \"stages.2.blocks.3.mlp.fc2.weight\", \"stages.2.blocks.3.mlp.fc2.bias\", \"stages.2.blocks.4.mlp.fc1.weight\", \"stages.2.blocks.4.mlp.fc1.bia...\n\tUnexpected key(s) in state_dict: \"stages.0.blocks.0.mlp.fc1.scale\", \"stages.0.blocks.0.mlp.fc1.zero_point\", \"stages.0.blocks.0.mlp.fc1._packed_params.dtype\", \"stages.0.blocks.0.mlp.fc1._packed_params._packed_params\", \"stages.0.blocks.0.mlp.fc2.scale\", \"stages.0.blocks.0.mlp.fc2.zero_point\", \"stages.0.blocks.0.mlp.fc2._packed_params.dtype\", \"stages.0.blocks.0.mlp.fc2._packed_params._packed_params\", \"stages.0.blocks.1.mlp.fc1.scale\", \"stages.0.blocks.1.mlp.fc1.zero_point\", \"stages.0.blocks.1.mlp.fc1._packed_params.dtype\", \"stages.0.blocks.1.mlp.fc1._packed_params._packed_params\", \"stages.0.blocks.1.mlp.fc2.scale\", \"stages.0.blocks.1.mlp.fc2.zero_point\", \"stages.0.blocks.1.mlp.fc2._packed_params.dtype\", \"stages.0.blocks.1.mlp.fc2._packed_params._packed_params\", \"stages.0.blocks.2.mlp.fc1.scale\", \"stages.0.blocks.2.mlp.fc1.zero_point\", \"stages.0.blocks.2.mlp.fc1._packed_params.dtype\", \"stages.0.blocks.2.mlp.fc1._packed_params._packed_params\", \"stages.0.blocks.2.mlp.fc2.scale\", \"stages.0.blocks.2.mlp.fc2.zero_point\", \"stages.0.blocks.2.mlp.fc2._packed_params.dtype\", \"stages.0.blocks.2.mlp.fc2._packed_params._packed_params\", \"stages.1.blocks.0.mlp.fc1.scale\", \"stages.1.blocks.0.mlp.fc1.zero_point\", \"stages.1.blocks.0.mlp.fc1._packed_params.dtype\", \"stages.1.blocks.0.mlp.fc1._packed_params._packed_params\", \"stages.1.blocks.0.mlp.fc2.scale\", \"stages.1.blocks.0.mlp.fc2.zero_point\", \"stages.1.blocks.0.mlp.fc2._packed_params.dtype\", \"stages.1.blocks.0.mlp.fc2._packed_params._packed_..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "MODEL_PATH = \"models/sem_int8.onnx\"\n",
        "\n",
        "CLASSES = [\"clean\",\"bridge\",\"cmp\",\"crack\",\"open\",\"ler\",\"via\",\"other\"]\n",
        "\n",
        "IMG_SIZE = 224\n",
        "OTHER_THRESHOLD = 0.65\n",
        "\n",
        "session = ort.InferenceSession(MODEL_PATH, providers=[\"CPUExecutionProvider\"])\n",
        "input_name = session.get_inputs()[0].name\n",
        "\n",
        "\n",
        "def preprocess(img_path):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    e = np.exp(x - np.max(x))\n",
        "    return e / np.sum(e)\n",
        "\n",
        "\n",
        "def infer(img_path):\n",
        "    x = preprocess(img_path)\n",
        "    out = session.run(None, {input_name: x})\n",
        "\n",
        "    logits = out[0][0]\n",
        "    probs = softmax(logits)\n",
        "\n",
        "    cls_id = int(np.argmax(probs))\n",
        "    conf = float(probs[cls_id])\n",
        "\n",
        "    pred = CLASSES[cls_id]\n",
        "\n",
        "    if conf < OTHER_THRESHOLD:\n",
        "        pred = \"other\"\n",
        "\n",
        "    return pred, conf\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    img = \"dataset/sample/test.png\"\n",
        "    print(infer(img))\n"
      ],
      "metadata": {
        "id": "DfWPggVnIFLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import psutil\n",
        "import time\n",
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "FP32_MODEL = \"models/sem.onnx\"\n",
        "INT8_MODEL = \"models/sem_int8.onnx\"\n",
        "\n",
        "CLASSES = [\"clean\",\"bridge\",\"cmp\",\"crack\",\"open\",\"ler\",\"via\",\"other\"]\n",
        "\n",
        "IMG_SIZE_HIGH = 224\n",
        "IMG_SIZE_LOW = 160\n",
        "\n",
        "CPU_THRESHOLD = 70\n",
        "\n",
        "session_fp32 = ort.InferenceSession(FP32_MODEL)\n",
        "session_int8 = ort.InferenceSession(INT8_MODEL)\n",
        "\n",
        "input_fp32 = session_fp32.get_inputs()[0].name\n",
        "input_int8 = session_int8.get_inputs()[0].name\n",
        "\n",
        "\n",
        "def preprocess(img_path, size):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (size, size))\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def softmax(x):\n",
        "    e = np.exp(x - np.max(x))\n",
        "    return e / np.sum(e)\n",
        "\n",
        "\n",
        "def auto_edge(img_path):\n",
        "    cpu = psutil.cpu_percent(interval=0.1)\n",
        "\n",
        "    if cpu > CPU_THRESHOLD:\n",
        "        session = session_int8\n",
        "        input_name = input_int8\n",
        "        size = IMG_SIZE_LOW\n",
        "        mode = \"INT8_LOW\"\n",
        "    else:\n",
        "        session = session_fp32\n",
        "        input_name = input_fp32\n",
        "        size = IMG_SIZE_HIGH\n",
        "        mode = \"FP32_HIGH\"\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    x = preprocess(img_path, size)\n",
        "    out = session.run(None, {input_name: x})\n",
        "\n",
        "    latency = time.time() - start\n",
        "\n",
        "    logits = out[0][0]\n",
        "    probs = softmax(logits)\n",
        "\n",
        "    cls_id = int(np.argmax(probs))\n",
        "    conf = float(probs[cls_id])\n",
        "\n",
        "    return {\n",
        "        \"class\": CLASSES[cls_id],\n",
        "        \"confidence\": conf,\n",
        "        \"mode\": mode,\n",
        "        \"latency\": latency,\n",
        "        \"cpu\": cpu\n",
        "    }\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(auto_edge(\"dataset/sample/test.png\"))\n"
      ],
      "metadata": {
        "id": "Plf2LdhqIJPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import os\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "TEST_PATH = \"dataset/test\"\n",
        "\n",
        "for cls in CLASSES:\n",
        "    folder = os.path.join(TEST_PATH, cls)\n",
        "\n",
        "    for img in os.listdir(folder):\n",
        "        path = os.path.join(folder, img)\n",
        "\n",
        "        pred, _ = infer(path)\n",
        "\n",
        "        y_true.append(cls)\n",
        "        y_pred.append(pred)\n",
        "\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "id": "tao3eomsIO0J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
